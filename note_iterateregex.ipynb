{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c842c70",
   "metadata": {},
   "source": [
    "\n",
    "- harder negatives\n",
    "    - assign harder negatives .. basically higher lvl keywords=0 if lower lvl severity label decided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electrical-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../notebooks\")\n",
    "\n",
    "import utils\n",
    "utils.jpt_autoreload()\n",
    "utils.jpt_full_width()\n",
    "utils.jpt_suppress_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "maritime-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from label_reports import get_chf_cohort, label_report\n",
    "from regex_utils import WordMatch\n",
    "\n",
    "from datasets import MimicCxrLabels, MimicCxrReader, MimicCxrBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norman-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_labels = MimicCxrLabels()\n",
    "cxr_reader = MimicCxrReader()\n",
    "meta_df = MimicCxrBase().get_meta_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intense-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'vascular congestion'),\n",
       " (1, 'vascular enlargement'),\n",
       " (1, 'vascular plethora'),\n",
       " (1, 'vascular engorgement'),\n",
       " (1, 'vascular prominence'),\n",
       " (1, 'cephalization'),\n",
       " (1, 'hilar congestion'),\n",
       " (1, 'hilar engorgement'),\n",
       " (1, 'hilar prominence'),\n",
       " (1, 'peribronchial cuffing'),\n",
       " (1, 'bronchial cuffing'),\n",
       " (1, 'bronchial wall thickening'),\n",
       " (2, 'septal lines'),\n",
       " (2, 'septal line'),\n",
       " (2, 'septal thickening'),\n",
       " (2, 'kerley'),\n",
       " (2, 'b lines'),\n",
       " (2, 'b-lines'),\n",
       " (2, 'b line'),\n",
       " (2, 'interstitial abnormality'),\n",
       " (2, 'interstitial abnormalities'),\n",
       " (2, 'interstitial marking'),\n",
       " (2, 'interstitial markings'),\n",
       " (2, 'interstitial infiltrates'),\n",
       " (2, 'interstitial opacities'),\n",
       " (2, 'interstitial thickening'),\n",
       " (2, 'interstitial process'),\n",
       " (2, 'interstitial edema'),\n",
       " (2, 'interstitial pulmonary edema'),\n",
       " (3, 'severe pulmonary edema'),\n",
       " (3, 'parenchymal opacity'),\n",
       " (3, 'parenchymal opacification'),\n",
       " (3, 'parenchymal opacities'),\n",
       " (3, 'parenchymal infiltrates'),\n",
       " (3, 'airspace opacity'),\n",
       " (3, 'airspace opacification'),\n",
       " (3, 'airspace opacities'),\n",
       " (3, 'airspace infiltrates'),\n",
       " (3, 'alveolar opacity'),\n",
       " (3, 'alveolar opacification'),\n",
       " (3, 'alveolar opacities'),\n",
       " (3, 'alveolar infiltrates')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = '.'\n",
    "# keyword terms for labeling pulmonary edema severity in a negated fashion\n",
    "#\n",
    "\n",
    "keywords_version = 'wpq' # 'miccai2020'\n",
    "opacitiesdeconfound = False\n",
    "negprec = False\n",
    "\n",
    "# pulmonary_edema_severity\tkeyword_terms\n",
    "# 0\tpulmonary edema\n",
    "# 0\tvascular congestion \n",
    "# 0\tfluid overload\n",
    "# 0\tacute cardiopulmonary process\n",
    "negated_keywords_path = os.path.join(current_path, 'keywords', keywords_version, 'keywords_negated.tsv')\n",
    "#\n",
    "# keyword terms for labeling pulmonary edema severity in a affirmed fashion\n",
    "# pulmonary_edema_severity\tkeyword_terms\n",
    "# 1\tcephalization\n",
    "# 1\tpulmonary vascular congestion\n",
    "# 1\thilar engorgement\n",
    "# etc.\n",
    "affirmed_keywords_path = os.path.join(current_path, 'keywords', keywords_version, 'keywords_affirmed.tsv')\n",
    "#\n",
    "# keyword terms for labeling pulmonary edema severity in a mentioned fashion\n",
    "# pulmonary_edema_severity\tkeyword_terms\n",
    "# 0\tno pulmonary edema\n",
    "# 0\tno vascular congestion\n",
    "# 0\tno fluid overload\n",
    "# 0\tno acute cardiopulmonary process\n",
    "mentioned_keywords_path = os.path.join(current_path, 'keywords', keywords_version, 'keywords_mentioned.tsv')\n",
    "\n",
    "opacity_keywords = [\n",
    "    'interstitial opacities',\n",
    "    'parenchymal opacities',\n",
    "    'alveolar opacities',\n",
    "    'ill defined opacities',\n",
    "    'ill-defined opacities',\n",
    "    'patchy opacities',\n",
    "]\n",
    "\n",
    "\n",
    "# the directory that contains reports for regex labeling\n",
    "report_dir = os.path.join(current_path, 'example_data')\n",
    "# CHF diagnosis information for mimic-cxr data\n",
    "chf_metadata_path = os.path.join(current_path, 'mimic_cxr_heart_failure', 'mimic_cxr_metadata_hf.tsv')\n",
    "# whether to limit the cohort to congestive heart failure\n",
    "limit_to_chf = True\n",
    "\n",
    "\n",
    "df_n = pd.read_csv(negated_keywords_path,  sep=\"\\t\")\n",
    "df_a = pd.read_csv(affirmed_keywords_path, sep=\"\\t\")\n",
    "df_m = pd.read_csv(mentioned_keywords_path, sep=\"\\t\")\n",
    "\n",
    "def keywords_label_to_list(df):\n",
    "    return df['pulmonary_edema_severity'].to_list(), df['keyword_terms'].to_list()\n",
    "\n",
    "df_chf = pd.read_csv(chf_metadata_path, sep='\\t')\n",
    "if limit_to_chf:\n",
    "    df_chf = df_chf[df_chf['heart_failure'] == 1]\n",
    "chf_study_ids = df_chf['study_id'].unique()\n",
    "print(len(chf_study_ids))\n",
    "\n",
    "\n",
    "list(zip(*keywords_label_to_list(df_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "oriental-mentor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 reports have been processed!\n",
      "2000 reports have been processed!\n",
      "3000 reports have been processed!\n",
      "4000 reports have been processed!\n",
      "5000 reports have been processed!\n",
      "6000 reports have been processed!\n",
      "7000 reports have been processed!\n",
      "8000 reports have been processed!\n",
      "9000 reports have been processed!\n",
      "10000 reports have been processed!\n",
      "11000 reports have been processed!\n",
      "12000 reports have been processed!\n",
      "13000 reports have been processed!\n",
      "14000 reports have been processed!\n",
      "15000 reports have been processed!\n",
      "16000 reports have been processed!\n",
      "17000 reports have been processed!\n",
      "took 6.8e+01s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>regex_label</th>\n",
       "      <th>relevant_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54577367</td>\n",
       "      <td>0</td>\n",
       "      <td>[pulmonary edema]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54980801</td>\n",
       "      <td>0</td>\n",
       "      <td>[acute cardiopulmonary process, no acute cardi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59988438</td>\n",
       "      <td>0</td>\n",
       "      <td>[vascular congestion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50109051</td>\n",
       "      <td>1</td>\n",
       "      <td>[vascular engorgement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51895247</td>\n",
       "      <td>0</td>\n",
       "      <td>[pulmonary edema]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>59159686</td>\n",
       "      <td>0</td>\n",
       "      <td>[pulmonary edema]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>54878259</td>\n",
       "      <td>3</td>\n",
       "      <td>[airspace opacities]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165</th>\n",
       "      <td>59281793</td>\n",
       "      <td>1</td>\n",
       "      <td>[vascular congestion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8166</th>\n",
       "      <td>59694089</td>\n",
       "      <td>1</td>\n",
       "      <td>[vascular congestion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>59735820</td>\n",
       "      <td>1</td>\n",
       "      <td>[vascular congestion]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8167 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      study_id  regex_label                                  relevant_keywords\n",
       "1     54577367            0                                  [pulmonary edema]\n",
       "2     54980801            0  [acute cardiopulmonary process, no acute cardi...\n",
       "3     59988438            0                              [vascular congestion]\n",
       "4     50109051            1                             [vascular engorgement]\n",
       "5     51895247            0                                  [pulmonary edema]\n",
       "...        ...          ...                                                ...\n",
       "8163  59159686            0                                  [pulmonary edema]\n",
       "8164  54878259            3                               [airspace opacities]\n",
       "8165  59281793            1                              [vascular congestion]\n",
       "8166  59694089            1                              [vascular congestion]\n",
       "8167  59735820            1                              [vascular congestion]\n",
       "\n",
       "[8167 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_study_ids = {}\n",
    "regex_labels = {}\n",
    "relevant_keywords = {}\n",
    "c = 0\n",
    "c_regex = 0\n",
    "c_labels = [0,0,0,0]\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# for i, (study_id, l) in enumerate(labels_prev.items()):\n",
    "# for i, (study_id, l) in enumerate(labels_prev):\n",
    "for i, study_id in enumerate(df_chf['study_id'].unique()):\n",
    "    study_id = int(study_id)\n",
    "\n",
    "    c_regex += 1\n",
    "    if c_regex%1000 == 0:\n",
    "        print(\"{} reports have been processed!\".format(c_regex))\n",
    "\n",
    "    try:\n",
    "        report = cxr_reader.get_report(study_id, remove_nextline=True)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # if has atlectasis/pneumonia, then do not use opacities for keyword search\n",
    "    \n",
    "    if opacitiesdeconfound:\n",
    "        \n",
    "        dicom_id = cxr_labels.df[cxr_labels.df['study_id']==study_id]['dicom_id'].to_list()\n",
    "        if len(dicom_id) != 0:\n",
    "            chex_labels = cxr_labels.get_chexpert_labels([dicom_id[0]])\n",
    "            has_confonding_variables = np.any(chex_labels[0,[0,11]]==1)\n",
    "            edema_binary = chex_labels[0,3]\n",
    "            if has_confonding_variables:\n",
    "                df_a_ = df_a[~df_a['keyword_terms'].isin(opacity_keywords)]\n",
    "            else:\n",
    "                df_a_ = df_a\n",
    "    else:\n",
    "        df_a_ = df_a\n",
    "\n",
    "    severities, keywords = keywords_label_to_list(df_a_)\n",
    "    label_a, severity_keywords_a = label_report(\n",
    "        report, severities, keywords, tag='affirmed')\n",
    "\n",
    "    severities, keywords = keywords_label_to_list(df_n)\n",
    "    label_n, severity_keywords_n = label_report(\n",
    "        report, severities, keywords, tag='negated')\n",
    "    \n",
    "    severities, keywords = keywords_label_to_list(df_m)\n",
    "    label_m, severity_keywords_m = label_report(\n",
    "        report, severities, keywords, tag='mentioned')\n",
    "    \n",
    "\n",
    "    # Negated condition takes precedence.\n",
    "    # Otherwise, takes the most severe condition\n",
    "    \n",
    "    if negprec:\n",
    "        if label_n == 0:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = max([label_a, label_n, label_m])\n",
    "    else:\n",
    "        label = max([label_a, label_n, label_m])\n",
    "\n",
    "    if label != -1:\n",
    "        c += 1\n",
    "        relevant_keywords[c] = severity_keywords_a[label] + severity_keywords_n[label] + severity_keywords_m[label]\n",
    "        labeled_study_ids[c] = study_id\n",
    "        regex_labels[c] = label\n",
    "        c_labels[label] += 1\n",
    "        \n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "print(f'took {end-start:.2}s')\n",
    "        \n",
    "        \n",
    "\n",
    "regex_df = pd.DataFrame(\n",
    "    {'study_id': labeled_study_ids,\n",
    "     'regex_label': regex_labels,\n",
    "     'relevant_keywords': relevant_keywords})\n",
    "output_csv_path = f'regex_results_{keywords_version}_negprec={negprec}_opacitiesdeconfound={opacitiesdeconfound}.tsv'\n",
    "regex_df.to_csv(output_csv_path, sep=\"\\t\")\n",
    "\n",
    "\n",
    "regex_df\n",
    "\n",
    "# \n",
    "# 1\tmild pulmonary edema ?\n",
    "# 2 moderate pulmonary edema ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "703c3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 FINAL REPORT\n",
      " REASON FOR EXAMINATION:  Evaluation of the patient with COPD and diastolic\n",
      " congestive heart failure with pulmonary edema.\n",
      " \n",
      " Ap chest radiograph.\n",
      " \n",
      " Since the prior study, there is progression of pre-existing pulmonary vascular\n",
      " congestion and upper zone re-distribution with currently added interstitial\n",
      " opacities, bronchial wall thickening and thickening of the minor fissure.  No\n",
      " interval increase in pleural effusion demonstrated, and no pneumothorax is\n",
      " seen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cxr_reader.get_report(study_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiac-kuwait",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "regex_df.to_csv(os.path.join('../../', 'notebooks', 'data', 'MimicCxrDataset', output_csv_path), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "secure-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/121 changed labels from regex to consensus image\n",
      "regex_results_miccai2020_negprec=False_opacitiesdeconfound=True.tsv\n",
      "  regex->ci    0    1    2    3\n",
      "-----------  ---  ---  ---  ---\n",
      "          0   25    9    0    1\n",
      "          1   11   15    5    4\n",
      "          2    8   10    8    2\n",
      "          3    8    5    4    6\n"
     ]
    }
   ],
   "source": [
    "# edema_df = cxr_labels.get_edema_df()\n",
    "# edema_df = edema_df[['dicom_id', 'EdemaSeverity']]\n",
    "# dfm = pd.merge(edema_df, regex_df, how='right', on=['dicom_id'], suffixes=('_regex', '_ci'))\n",
    "consensus_df = pd.read_csv(\n",
    "    '/data/vision/polina/scratch/wpq/github/interpretability/notebooks/data/MimicCxrDataset/consensus_image_edema_severity.csv')\n",
    "dfm = pd.merge(consensus_df, regex_df, how='right', on=['study_id'])\n",
    "print(f\"{len(dfm[dfm['edema_severity']!=dfm['regex_label']])}/{len(dfm)} changed labels from regex to consensus image\")\n",
    "\n",
    "# Table\n",
    "a = np.zeros((4,4))\n",
    "for x in range(4):\n",
    "    for y in range(4):\n",
    "        dfs = dfm[(dfm['regex_label']==x)&(dfm['edema_severity']==y)]\n",
    "        a[x,y]=len(dfs)\n",
    "        \n",
    "        if x == 0 and y == 2 and len(dfs)>0:\n",
    "            print(dfs['study_id'].to_list()[0])\n",
    "        \n",
    "from tabulate import tabulate\n",
    "print(output_csv_path)\n",
    "print(tabulate(np.hstack((np.arange(4).reshape(-1,1), a)), headers=['regex->ci', 0,1,2,3]))\n",
    "\n",
    "\n",
    "# regex_results_miccai2020\n",
    "# 76/132 changed labels from regex to consensus image\n",
    "#   regex->ci    0    1    2    3\n",
    "# -----------  ---  ---  ---  ---\n",
    "#           0   25    8    0    1\n",
    "#           1   11   15    5    4\n",
    "#           2    8   10    7    2\n",
    "#           3   11    9    7    9\n",
    "#\n",
    "# 74/132 changed labels from regex to consensus image\n",
    "# regex_results_miccai2020_negprec=True_opacitiesdeconfound=False.tsv\n",
    "#   regex->ci    0    1    2    3\n",
    "# -----------  ---  ---  ---  ---\n",
    "#           0   28   10    3    2\n",
    "#           1   10   14    4    3\n",
    "#           2    7   10    7    2\n",
    "#           3   10    8    5    9\n",
    "#\n",
    "# 65/121 changed labels from regex to consensus image\n",
    "# regex_results_miccai2020_negprec=True_opacitiesdeconfound=True.tsv\n",
    "#   regex->ci    0    1    2    3\n",
    "# -----------  ---  ---  ---  ---\n",
    "#           0   28   10    3    2\n",
    "#           1   10   14    4    3\n",
    "#           2    7   10    8    2\n",
    "#           3    7    5    2    6\n",
    "#\n",
    "# 67/121 changed labels from regex to consensus image\n",
    "# regex_results_miccai2020_negprec=False_opacitiesdeconfound=True.tsv\n",
    "#   regex->ci    0    1    2    3\n",
    "# -----------  ---  ---  ---  ---\n",
    "#           0   25    9    0    1\n",
    "#           1   11   15    5    4\n",
    "#           2    8   10    8    2\n",
    "#           3    8    5    4    6\n",
    "\n",
    "# # remove opacities keyword\n",
    "# 92/141 changed labels from regex to consensus image\n",
    "#   regex->ci    0    1    2    3\n",
    "# -----------  ---  ---  ---  ---\n",
    "#           0   26    9    2    1\n",
    "#           1   11   15    5    4\n",
    "#           2    9   10    8    2\n",
    "#           3    0    0    0    0   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "random-georgia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = cxr_labels.df\n",
    "# dft = df[(df['split']=='train')&(df['EdemaSeverity'].notnull())]\n",
    "# # dft = df[df['EdemaSeverity'].notnull()]\n",
    "# SId, studlabels_prev = dft[['study_id', 'EdemaSeverity']]\n",
    "# counts = 0\n",
    "# for i, (study_id, l) in enumerate(dft[['study_id', 'EdemaSeverity']].set_index('study_id')['EdemaSeverity'].to_dict().items()):\n",
    "\n",
    "#     if i%1000 == 0:\n",
    "#         print(\"{} reports have been processed!\".format(i))\n",
    "\n",
    "#     report = cxr_reader.get_report(study_id, remove_nextline=True)\n",
    "# #     if 'severe pulmonary edema' in report:\n",
    "#     if 'patchy opacities' in report:\n",
    "#         counts += 1\n",
    "        \n",
    "# print(counts)\n",
    "        \n",
    "        \n",
    "# # 35 reports in training has alveolar opacities\n",
    "\n",
    "# # parenchymal opacities\n",
    "# # train: 223, all: 278\n",
    "# # patchy opacities\n",
    "# # train: 74, all: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "proprietary-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 FINAL REPORT\n",
      " EXAMINATION:  CHEST (PA AND LAT)\n",
      " \n",
      " INDICATION:  ___ year old woman with presyncope, congestive heart failure,\n",
      " end-stage renal disease.\n",
      " \n",
      " TECHNIQUE:  Chest PA and lateral\n",
      " \n",
      " COMPARISON:  Chest radiograph ___\n",
      " \n",
      " FINDINGS: \n",
      " \n",
      " Right-sided dual lumen central venous catheter tip terminates in the right\n",
      " atrium, unchanged.  Mild to moderate enlargement of the cardiac silhouette is\n",
      " re- demonstrated.  The mediastinal contour is unchanged.  Moderate pulmonary\n",
      " edema is present, similar to that seen on the prior exam, with a new small\n",
      " left pleural effusion.  Patchy opacities in the lung bases likely reflect\n",
      " areas of atelectasis.  No pneumothorax is present.  Clips project over the\n",
      " left axilla.  There are no acute osseous abnormalities.\n",
      " \n",
      " IMPRESSION: \n",
      " \n",
      " Moderate pulmonary edema, similar to the previous study, with new small left\n",
      " pleural effusion.  Bibasilar atelectasis.\n",
      "\n",
      "-1 0 -1\n"
     ]
    }
   ],
   "source": [
    "# negprec ... some makes sense, some not ... will only hurt pulmonary vascular congestion but otherwise helps reduce opacities FP\n",
    "# 58988106   Right upper lobe parenchymal opacities are grossly unchanged from ___.  No superimposed acute cardiopulmonary process.\n",
    "# 51397090\n",
    "# 50145470   Unchanged pulmonary vascular congestion without overt pulmonary edema. ... \n",
    "# 53919055   Pulmonary vascular congestion without overt pulmonary edema.\n",
    "# 50762469   pulmonary vascular congestion\n",
    "# 52853233   \n",
    "# 54393504   Chronic changes in the lungs without definite superimposed acute  cardiopulmonary process.\n",
    "# 54594082   Patchy opacities in the lung bases may reflect atelectasis though infection, no overt pulmonary edema. \n",
    "# 52549668   No definitive evidence of acute cardiopulmonary process. \n",
    "study_id = 58430521\n",
    "print(cxr_reader.get_report(study_id))\n",
    "\n",
    "if opacitiesdeconfound:\n",
    "    chex_labels = cxr_labels.get_chexpert_labels(\n",
    "        [cxr_labels.df[cxr_labels.df['study_id']==study_id]['dicom_id'].to_list()[0]])\n",
    "    has_confonding_variables = np.any(chex_labels[0,[0,11]]==1)\n",
    "    edema_binary = chex_labels[0,3]\n",
    "    if has_confonding_variables:\n",
    "        df_a_ = df_a[~df_a['keyword_terms'].isin(opacity_keywords)]\n",
    "    else:\n",
    "        df_a_ = df_a\n",
    "else:\n",
    "    df_a_ = df_a\n",
    "\n",
    "severities, keywords = keywords_label_to_list(df_a_)\n",
    "label_a, severity_keywords_a = label_report(\n",
    "    report, severities, keywords, tag='affirmed')\n",
    "\n",
    "severities, keywords = keywords_label_to_list(df_n)\n",
    "label_n, severity_keywords_n = label_report(\n",
    "    report, severities, keywords, tag='negated')\n",
    "\n",
    "severities, keywords = keywords_label_to_list(df_m)\n",
    "label_m, severity_keywords_m = label_report(\n",
    "    report, severities, keywords, tag='mentioned')\n",
    "\n",
    "print(label_a, label_n, label_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cxr] *",
   "language": "python",
   "name": "conda-env-cxr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
